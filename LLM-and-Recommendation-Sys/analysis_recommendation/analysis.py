#!/usr/bin/env python
"""
Analysis Module for SmartBeauty Product Recommendations

This module:
1. Fetches user skin analysis data from API
2. Filters analysis results by confidence threshold
3. Maps analysis types to skin concerns using embeddings
4. Calculates product scores based on concern similarities and confidence
5. Returns top recommended products with allergen filtering

Usage:
python analysis.py --user_id 2 [--threshold 0.5] [--top_n 10]
"""

import os
import sys
import argparse
import json
from typing import List, Dict, Tuple, Optional
from datetime import datetime

# Add parent directory to path for imports
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, parent_dir)

from utility.get_analysis import get_user_analysis
from filtering_products.allergen_filtering import AllergenFilter
from mapping import SPECIAL_MAPPINGS, BeautyPreferencesSkinConcern
from db.connection import get_database_manager


class ProductAnalysisModule:
    """
    Main analysis module for product recommendations based on skin analysis.
    
    This module integrates:
    - Skin analysis confidence filtering
    - Concern-to-embedding similarity matching
    - Allergen filtering
    - Weighted product scoring
    """
    
    def __init__(self, confidence_threshold: float = 0.5):
        """
        Initialize the analysis module.
        
        Args:
            confidence_threshold: Minimum confidence score for analysis results (0.0-1.0)
        """
        self.confidence_threshold = confidence_threshold
        self.allergen_filter = AllergenFilter()
        self.concern_embeddings_cache = {}  # Cache for concern embeddings
    
    def analyze_and_recommend(
        self, 
        user_id: int,
        top_n: int = 10,
        max_price: float = None,
        include_out_of_stock: bool = False
    ) -> Dict:
        """
        Complete analysis and recommendation pipeline.
        
        Args:
            user_id: User ID for analysis
            top_n: Number of top products to return
            max_price: Optional maximum price filter
            include_out_of_stock: Whether to include out-of-stock products
            
        Returns:
            Dictionary with analysis results and product recommendations
        """
        print(f"üîç Starting analysis for user {user_id}")
        print(f"   Confidence threshold: {self.confidence_threshold}")
        print(f"   Top products: {top_n}")
        print(f"   Max price: ${max_price}" if max_price else "   No price limit")
        
        # Step 1: Get and filter analysis data
        print(f"\nüìä Step 1: Fetching and filtering analysis data...")
        filtered_analysis = self._get_filtered_analysis(user_id)
        
        if not filtered_analysis:
            return {
                'user_id': user_id,
                'analysis_summary': {'message': 'No analysis data above threshold'},
                'products': []
            }
        
        # Step 2: Map analysis types to concerns
        print(f"\nüó∫Ô∏è  Step 2: Mapping analysis to skin concerns...")
        concern_scores = self._map_analysis_to_concerns(filtered_analysis)
        
        # Step 3: Get concern embeddings
        print(f"\nüß† Step 3: Retrieving concern embeddings...")
        concern_embeddings = self._get_concern_embeddings(list(concern_scores.keys()))
        
        # Step 4: Get allergen filter components
        print(f"\nüõ°Ô∏è  Step 4: Setting up allergen filtering...")
        allergen_where, allergen_params = self._get_allergen_filter(user_id)
        
        # Step 5: Calculate product scores
        print(f"\nüéØ Step 5: Calculating product scores...")
        products = self._calculate_product_scores(
            concern_embeddings=concern_embeddings,
            concern_scores=concern_scores,
            allergen_where=allergen_where,
            allergen_params=allergen_params,
            top_n=top_n,
            max_price=max_price,
            include_out_of_stock=include_out_of_stock
        )
        
        # Step 6: Compile results
        analysis_summary = self._create_analysis_summary(filtered_analysis, concern_scores)
        
        return {
            'user_id': user_id,
            'analysis_summary': analysis_summary,
            'products': products,
            'parameters': {
                'confidence_threshold': self.confidence_threshold,
                'top_n': top_n,
                'max_price': max_price,
                'include_out_of_stock': include_out_of_stock
            }
        }
    
    def _get_filtered_analysis(self, user_id: int) -> List[Dict]:
        """Get analysis data and filter by confidence threshold"""
        print(f"  üì° Fetching analysis data...")
        
        analysis_data = get_user_analysis(user_id)
        if not analysis_data or not analysis_data.get('success'):
            print(f"  ‚ùå Failed to get analysis data")
            return []
        
        raw_analysis = analysis_data.get('data', [])
        print(f"  üìã Raw analysis items: {len(raw_analysis)}")
        
        # Filter by confidence threshold
        # Note: Some confidence values might be 0-100 scale, others 0-1 scale
        filtered = []
        for item in raw_analysis:
            confidence = item.get('confidence', 0)
            analysis_type = item.get('analysisType', '')
            
            # Normalize confidence to 0-1 scale
            if confidence > 1:
                normalized_confidence = confidence / 100.0
            else:
                normalized_confidence = confidence
            
            if normalized_confidence >= self.confidence_threshold:
                item['normalized_confidence'] = normalized_confidence
                filtered.append(item)
                print(f"    ‚úÖ {analysis_type}: {confidence} ‚Üí {normalized_confidence:.3f}")
            else:
                print(f"    ‚ùå {analysis_type}: {confidence} ‚Üí {normalized_confidence:.3f} (below threshold)")
        
        print(f"  üìä Filtered analysis items: {len(filtered)}")
        return filtered
    
    def _map_analysis_to_concerns(self, analysis_data: List[Dict]) -> Dict[str, float]:
        """Map analysis types to skin concerns with weighted scores"""
        print(f"  üó∫Ô∏è  Mapping {len(analysis_data)} analysis items to concerns...")
        
        concern_scores = {}
        
        for item in analysis_data:
            analysis_type = item.get('analysisType', '').lower()
            confidence = item.get('normalized_confidence', 0)
            
            # Direct mapping - analysis type becomes concern name
            # The robust matching in _get_concern_embeddings will handle finding the right concept
            concern_scores[analysis_type] = concern_scores.get(analysis_type, 0) + confidence
            print(f"    üìç {analysis_type} ‚Üí {analysis_type} (confidence: {confidence:.3f})")
        
        print(f"  üìä Final concern scores:")
        for concern, score in concern_scores.items():
            print(f"    {concern}: {score:.3f}")
        
        return concern_scores
    
    def _get_concern_embeddings(self, concern_names: List[str]) -> Dict[str, List[float]]:
        """Get embeddings for concerns from the concepts table with robust matching"""
        print(f"  üß† Retrieving embeddings for {len(concern_names)} concerns...")
        
        concern_embeddings = {}
        
        try:
            with get_database_manager().get_db_connection() as conn:
                with conn.cursor() as cursor:
                    # Get all available concepts first for better matching
                    cursor.execute("""
                    SELECT name, embedding 
                    FROM concepts 
                    WHERE embedding IS NOT NULL
                    ORDER BY name
                    """)
                    
                    available_concepts = cursor.fetchall()
                    print(f"    üìã Available concepts: {[name for name, _ in available_concepts]}")
                    
                    for concern in concern_names:
                        matched_concept = None
                        
                        # Try multiple matching strategies
                        normalized_concern = concern.lower().replace(' ', '').replace('-', '').replace('_', '')
                        
                        for concept_name, embedding in available_concepts:
                            normalized_concept = concept_name.lower().replace(' ', '').replace('-', '').replace('_', '')
                            
                            # Strategy 1: Exact match after normalization
                            if normalized_concern == normalized_concept:
                                matched_concept = (concept_name, embedding)
                                break
                            
                            # Strategy 2: Concern contains concept or vice versa
                            elif (normalized_concern in normalized_concept or 
                                  normalized_concept in normalized_concern):
                                matched_concept = (concept_name, embedding)
                                break
                            
                            # Strategy 3: Special known mappings based on actual database content
                            elif self._is_concept_match(normalized_concern, normalized_concept):
                                matched_concept = (concept_name, embedding)
                                break
                        
                        if matched_concept:
                            concept_name, embedding = matched_concept
                            
                            # Convert PostgreSQL vector to Python list
                            if embedding:
                                embedding_str = str(embedding)
                                if embedding_str.startswith('[') and embedding_str.endswith(']'):
                                    embedding_list = [float(x.strip()) for x in embedding_str[1:-1].split(',')]
                                    concern_embeddings[concern] = embedding_list
                                    print(f"    ‚úÖ {concern} ‚Üí {concept_name} (embedding: {len(embedding_list)}D)")
                                else:
                                    print(f"    ‚ö†Ô∏è  {concern} ‚Üí {concept_name} (invalid embedding format)")
                            else:
                                print(f"    ‚ö†Ô∏è  {concern} ‚Üí {concept_name} (no embedding)")
                        else:
                            print(f"    ‚ùå {concern} ‚Üí No matching concept found")
        
        except Exception as e:
            print(f"  ‚ùå Database error: {e}")
        
        print(f"  üìä Retrieved {len(concern_embeddings)} concern embeddings")
        return concern_embeddings
    
    def _is_concept_match(self, concern: str, concept: str) -> bool:
        """Check if concern matches concept using known mappings"""
        # Known mappings based on actual database concepts
        mappings = {
            'darkcircles': 'darkcircles',
            'puffiness': 'eyebag',  # puffiness maps to Eyebag concept
            'finelines': 'wrinkles',
            'finelineswrinkles': 'wrinkles',
            'acneblemishes': 'acne',  # This exists as 'Acne' in database
            'blemishes': 'acne'
        }
        
        return mappings.get(concern) == concept
    
    def _get_allergen_filter(self, user_id: int) -> Tuple[str, List[str]]:
        """Get allergen filter SQL components"""
        print(f"  üõ°Ô∏è  Setting up allergen filtering...")
        
        # Get user allergens
        allergen_names, _ = self.allergen_filter.get_user_allergens(user_id)
        
        if not allergen_names:
            print(f"    ‚úÖ No allergen restrictions")
            return "", []
        
        # Generate search terms
        search_terms = self.allergen_filter.generate_search_terms(allergen_names)
        
        # Get SQL components
        where_clause, params = self.allergen_filter.generate_allergen_filter_sql(
            search_terms, exclude_unsafe=True
        )
        
        print(f"    üõ°Ô∏è  Allergen filter active: {len(allergen_names)} allergens")
        return where_clause, params
    
    def _calculate_product_scores(
    self,
    concern_embeddings: Dict[str, List[float]],
    concern_scores: Dict[str, float],
    allergen_where: str,
    allergen_params: List[str],
    top_n: int,
    max_price: Optional[float],
    include_out_of_stock: bool
    ) -> List[Dict]:
        """Calculate weighted product scores using a single, unified SQL query."""
        print(f"  üéØ Calculating product scores using a single query...")
    
        if not concern_embeddings:
            print("    ‚ö†Ô∏è  No concern embeddings available, cannot score products.")
            return []

        # --- Step 1: Build the components for the single query ---

        # Build the dynamic scoring formula for the ORDER BY clause
        # Example: (0.9 * (1 - (embedding <=> '[acne_vec]'))) + (0.7 * (1 - (embedding <=> '[redness_vec]')))
        score_clauses = []
        query_params = []  # Use list for positional parameters - simpler and more compatible
        param_index = 0

        for concern_name, embedding in concern_embeddings.items():
            weight = concern_scores.get(concern_name, 0)
            # Convert distance to similarity: 1 - distance
            score_clauses.append(f"({weight} * (1 - (embedding <=> %s::vector)))")
            query_params.append(str(embedding))
            param_index += 1

        scoring_formula = " + ".join(score_clauses)

        # Build the WHERE clause
        where_conditions = ["embedding IS NOT NULL"]
        
        if allergen_where:
            where_conditions.append(f"({allergen_where})")
            query_params.extend(allergen_params)

        if max_price:
            where_conditions.append("price <= %s")
            query_params.append(max_price)

        if not include_out_of_stock:
            where_conditions.append("stock_status = 0")

        where_clause = "WHERE " + " AND ".join(where_conditions)

        # --- Step 2: Assemble the final query ---
        
        final_query = f"""
        SELECT
            id, name, key_benefits, description, price, stock_status,
            ({scoring_formula}) AS final_score
        FROM products
        {where_clause}
        ORDER BY final_score DESC -- DESC because we want higher similarity scores
        LIMIT %s
        """
        query_params.append(top_n)

        # --- Step 3: Execute the query ---

        products = []
        try:
            with get_database_manager().get_db_connection() as conn:
                with conn.cursor() as cursor:
                    # Use positional parameters
                    cursor.execute(final_query, query_params)
                    results = cursor.fetchall()

                    print(f"      üìà Found {len(results)} top products in a single query.")
                    
                    for row in results:
                        (product_id, name, benefits, description, price, 
                        stock_status, total_score) = row
                        
                        products.append({
                            'id': product_id,
                            'name': name,
                            'key_benefits': benefits,
                            'description': description,
                            'price': float(price) if price else 0.0,
                            'stock_status': stock_status,
                            'in_stock': stock_status == 0,
                            'total_score': float(total_score) if total_score else 0.0,
                            'concern_scores': {} # Individual concern breakdown not available in single query
                        })
        except Exception as e:
            print(f"  ‚ùå Database error: {e}")
            # Debug information
            print("Query:", final_query)
            print("Parameters:", query_params[:5], "..." if len(query_params) > 5 else "")
            return []

        print(f"  ‚úÖ Calculated scores, returning top {len(products)} products.")
        return products
    
    def _create_analysis_summary(self, filtered_analysis: List[Dict], concern_scores: Dict[str, float]) -> Dict:
        """Create summary of analysis results"""
        return {
            'total_analysis_items': len(filtered_analysis),
            'confidence_threshold': self.confidence_threshold,
            'analysis_items': [
                {
                    'type': item.get('analysisType'),
                    'confidence': item.get('confidence'),
                    'normalized_confidence': item.get('normalized_confidence'),
                    'created_at': item.get('createdAt')
                }
                for item in filtered_analysis
            ],
            'mapped_concerns': concern_scores,
            'top_concerns': sorted(concern_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        }


def display_results(results: Dict, verbose: bool = False):
    """Display analysis results in a user-friendly format"""
    print(f"\n{'='*80}")
    print(f"üìä PRODUCT ANALYSIS RESULTS FOR USER {results['user_id']}")
    print(f"{'='*80}")
    
    # Analysis summary
    summary = results['analysis_summary']
    if 'message' in summary:
        print(f"üìã {summary['message']}")
        return
    
    print(f"üìã Analysis Summary:")
    print(f"   Confidence threshold: {summary['confidence_threshold']}")
    print(f"   Analysis items processed: {summary['total_analysis_items']}")
    print(f"   Top concerns: {', '.join([f'{c}({s:.2f})' for c, s in summary['top_concerns']])}")
    
    # Product results
    products = results['products']
    print(f"\nüéØ Top {len(products)} Recommended Products:")
    print(f"{'-'*80}")
    
    for i, product in enumerate(products, 1):
        print(f"{i}. {product['name']} (ID: {product['id']})")
        print(f"   Score: {product['total_score']:.4f} | Price: ${product['price']:.2f}")
        print(f"   Stock: {'‚úÖ In Stock' if product['in_stock'] else '‚ùå Out of Stock'}")
        
        if verbose:
            print(f"   Benefits: {product['key_benefits'][:100]}..." if product.get('key_benefits') else "")
            print(f"   Concern breakdown:")
            for concern, scores in product['concern_scores'].items():
                print(f"     - {concern}: similarity={scores['similarity']:.3f}, weight={scores['weight']:.3f}, score={scores['weighted_score']:.4f}")
        
        print()


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Analyze skin concerns and recommend products")
    parser.add_argument("--user_id", type=int, required=True, help="User ID for analysis")
    parser.add_argument("--threshold", type=float, default=0.5, help="Confidence threshold (0.0-1.0)")
    parser.add_argument("--top_n", type=int, default=10, help="Number of top products to return")
    parser.add_argument("--max_price", type=float, help="Maximum product price")
    parser.add_argument("--include_out_of_stock", action="store_true", help="Include out-of-stock products")
    parser.add_argument("--verbose", "-v", action="store_true", help="Show detailed results")
    parser.add_argument("--output", help="Output file for results (JSON)")
    return parser.parse_args()


def main():
    """Main function"""
    args = parse_args()
    
    print(f"üß™ SmartBeauty Product Analysis Module")
    print(f"{'='*50}")
    
    # Initialize analysis module
    analysis_module = ProductAnalysisModule(confidence_threshold=args.threshold)
    
    # Run analysis and recommendations
    results = analysis_module.analyze_and_recommend(
        user_id=args.user_id,
        top_n=args.top_n,
        max_price=args.max_price,
        include_out_of_stock=args.include_out_of_stock
    )
    
    # Display results
    display_results(results, verbose=args.verbose)
    
    # Save results if requested
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"üíæ Results saved to {args.output}")


if __name__ == "__main__":
    main()
